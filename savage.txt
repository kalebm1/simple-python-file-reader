Kaleb Morgan CSC 3200 In my opinion, disinformation in cyberspace is a huge problem both for our society and our health. "Fake news" has caused many friends and families to drift apart from each other and even unnecessary stress and anxiety. Many people base their entire beliefs towards a subject on what they read online, which is an alarming thought in today's age. With the accessibility of the internet, anyone who has a computer or a smartphone can spread whatever message they believe in. What was once thought of as being a catalyst to democracy, as the case study suggests, has now become a massive mix of real and fake information that is becoming increasingly difficult to navigate. Disinformation has led to heavy political polarization, the radicalization of certain ideals, and the adoption of made-up beliefs. This detrimental shortcoming will continue to ravage through websites and social media platforms unless there are practices and policies put in place by hosting providers, social media platforms, and media editors to limit the spread of misinformation across cyberspace. From a modern perspective, disinformation has been a critical component in how people view the seriousness of the current pandemic. I personally know many friends who have been exposed to disinformation online and have come to the conclusion that COVID-19 is not a critical issue for the country. This problem is a widespread issue that will likely lead to many people opting not to be vaccinated when there is a viable vaccine. This example may not seem too serious, but it puts compromised people at direct risk to lose their lives to the novel Coronavirus. This is just one of the many examples of fake information leading to the loss of lives. One political example of fake information leading to highly polarized viewpoints that divided the nation was seen in the recent political events surrounding the death of George Floyd. After the unjust death of George Floyd, many "fake news" outlets released stories that spun the story back onto George Floyd and made him seem like the villain of the story. This was taken by one side of the country to justify the death and the other side to fuel their hatred of their counterparts. The protests that ensued from the death of George Floyd was also plagued with disinformation that only added to the flames that separated the country. These stories and posts that were published to mislead the nation only caused hatred and polarization across the country and likely irreparable damage to the relationships of many. While these problems would not be completely eliminated with limiting factors on disinformation, it would not be as widespread as it has become in recent times. The main problem that is hindering many companies to take action against disinformation is the belief that "fake news" online is covered under the first amendment, which deters many companies from taking serious action against disinformation. Companies' lack of action only adds to the fire that is disinformation and allows for the further spread of this dangerous information. One sad reality of stopping the spread of disinformation is that platforms will most likely lose users or customers with any changes to their policies on "fake news". One company that has frequently been in the headlines when it comes to "fake news" is Facebook. Facebook has recently implemented a few policies against the spread of "fake news" that I believe has slightly helped in slowing the spread of disinformation. Specifically, their overlay system that notifies readers that the post they are reading may include false information is a great start in slowing the spread of misinformation. I believe that Facebook should heavily tighten their stance and policies towards dealing with fake information on their platform. These policies may not be widely accepted by users, but they are extremely important in ensuring the halt of disinformation. One policy that I would suggest Facebook adopt to limit the publishing of disinformation is a strict no-tolerance policy towards disinformation. This could include building on top of their current system to identify misinformation and adding a manual review process once misinformation is identified. Once the information is reviewed and confirmed to be "fake news", Facebook should implement a type of suspension system that would give users two or three chances before their account being permanently blocked from posting content on the website. While manual reviews would be costly, it is imperative to ensure that true information is not mislabeled and that disinformation is closer to be eradicated on the platform. One way that Facebook could circumvent the massive job of manually reviewing claims of false information would be to open a peer-review system where users can volunteer to review posts of "fake news". Facebook could incentivize users to sign up for this by offering either a money reward per review, or by collaborating with other organizations to offer gift cards, prize packages, or coupons to redeem in-store. These incentives would hopefully lead to a large number of users opting to volunteer to review these claims of "fake news" which would take some of the complications off of Facebook directly. This opportunity, depending on the size of the incentives offered by Facebook, could provide slight relief to some members of the society who have been impacted by the current pandemic. This outcome would ultimately lead to positive news and an overall good outcome for Facebook. One final policy that I would recommend Facebook implement for stopping the spread of fake information is to add extra resources for people to be able to discern real news and "fake news". One of these resources could be warning users when they are following a link to a website that has been known to post fake information before. Another resource they could offer more of that they have already started doing is posting the real information of frequent "fake news" stories in a public place that is prominent to users. An example of this could be similar to Facebook's "Learn about the facts of COVID-19" banners they added at the top of their newsfeed. They can expand on this resource by adding it in more places in the newsfeed and replacing some advertising slots with real news stories about the popular disinformation stories at the time. Disinformation is a critical issue that is plaguing cyberspace and all countries and civilizations worldwide. If it is not controlled soon, it could lead to many problems including the increasing difficulty of discerning between real and fake information. Many companies must pledge to take action against the spread of disinformation in order for anything to change. Social media platforms, such as Facebook, have a unique responsibility to adapt policies and resources to stop the spread of fake information.
